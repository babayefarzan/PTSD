{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n",
    "pca_importance =['T1ETBE',\n",
    " 'T1bias',\n",
    " 'state1',\n",
    " 'trait1',\n",
    " 'PCL1',\n",
    " 'cd_risc1',\n",
    " 'Ashken_scale',\n",
    " 'Sephar_scale',\n",
    " 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\", \"T1ETBE\", \"T1Acc1t\",\n",
    "                         \"T1Acc1n\", \"T1bias\", \"T2Acc1t\", \"T2Acc1n\", \"T2bias\", \"state1\", \"state2\", \"trait1\",\n",
    "                         \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"PCL1\", \"PCL2\", \"cd_risc1\", \"ptgi2\",\n",
    "                         \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                         \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                         \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                         \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                         \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                         \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                         \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                         \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                         \"Sephar_scale\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HML_5HTT</th>\n",
       "      <th>HL_MAOA</th>\n",
       "      <th>HML_NPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HML_5HTT  HL_MAOA  HML_NPY\n",
       "0          2.0      1.0      2.0\n",
       "1          3.0      2.0      3.0\n",
       "2          2.0      1.0      2.0\n",
       "3          2.0      2.0      1.0\n",
       "4          2.0      2.0      1.0\n",
       "6          3.0      2.0      3.0\n",
       "7          2.0      2.0      1.0\n",
       "8          1.0      1.0      3.0\n",
       "9          2.0      2.0      1.0\n",
       "10         2.0      2.0      2.0\n",
       "11         3.0      2.0      1.0\n",
       "12         1.0      2.0      2.0\n",
       "13         2.0      2.0      1.0\n",
       "14         3.0      1.0      1.0\n",
       "16         3.0      2.0      1.0\n",
       "19         NaN      NaN      NaN\n",
       "20         1.0      2.0      2.0\n",
       "21         1.0      2.0      3.0\n",
       "23         2.0      2.0      3.0\n",
       "25         1.0      1.0      3.0\n",
       "28         2.0      2.0      1.0\n",
       "29         NaN      NaN      NaN\n",
       "31         2.0      1.0      2.0\n",
       "33         3.0      1.0      2.0\n",
       "34         1.0      2.0      2.0\n",
       "35         NaN      NaN      NaN\n",
       "36         2.0      2.0      3.0\n",
       "37         3.0      2.0      3.0\n",
       "38         3.0      2.0      2.0\n",
       "39         3.0      1.0      3.0\n",
       "...        ...      ...      ...\n",
       "1066       3.0      2.0      1.0\n",
       "1067       2.0      2.0      3.0\n",
       "1068       NaN      NaN      NaN\n",
       "1069       2.0      2.0      2.0\n",
       "1071       2.0      2.0      1.0\n",
       "1072       2.0      2.0      2.0\n",
       "1073       1.0      2.0      2.0\n",
       "1075       2.0      2.0      2.0\n",
       "1076       NaN      NaN      NaN\n",
       "1078       1.0      1.0      3.0\n",
       "1080       2.0      1.0      3.0\n",
       "1082       2.0      1.0      1.0\n",
       "1083       3.0      1.0      2.0\n",
       "1084       2.0      2.0      1.0\n",
       "1085       3.0      2.0      2.0\n",
       "1088       1.0      2.0      1.0\n",
       "1089       1.0      2.0      3.0\n",
       "1090       1.0      1.0      2.0\n",
       "1091       3.0      2.0      1.0\n",
       "1092       1.0      1.0      2.0\n",
       "1093       NaN      NaN      NaN\n",
       "1094       3.0      2.0      3.0\n",
       "1095       2.0      2.0      3.0\n",
       "1096       3.0      2.0      2.0\n",
       "1097       2.0      1.0      1.0\n",
       "1098       3.0      2.0      1.0\n",
       "1099       1.0      1.0      1.0\n",
       "1100       2.0      2.0      2.0\n",
       "1101       2.0      2.0      2.0\n",
       "1102       3.0      1.0      2.0\n",
       "\n",
       "[725 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [ \"T1ETBE\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"T2Acc1t\",\"T2Acc1n\", \"T2bias\", \"state1\", \"state2\",\n",
    "                        \"trait1\", \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"cd_risc1\", \"PCL1\", \"PCL2\"]\n",
    "categorical_features = [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\",   \"ptgi2\",\n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                    \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                    \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                    \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                    \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                    \"Sephar_scale\", \"Unknown\"]\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "#X = df[features]\n",
    "X = df[features]\n",
    "Y = df[\"PCL3\"] > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.15, random_state=271828, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=27)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components = 0.99)\n",
    "#X_train_res = pca.fit_transform(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.88690476 0.97311828 0.96216216]\n",
      "recall_score 0.9855072463768116\n",
      "precision_score 0.9855072463768116\n",
      "accuracy_score 0.9967532467532467\n",
      "f1_score 0.9855072463768116\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "score = cross_val_score(clf, X_train_res, y_train_res, scoring=\"f1\")\n",
    "print(\"score\", score)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "y_pred = clf.predict(X_train)\n",
    "print(\"recall_score\", recall_score(y_pred,y_train))\n",
    "print(\"precision_score\",precision_score(y_pred,y_train))\n",
    "print(\"accuracy_score\",accuracy_score(y_pred,y_train))\n",
    "print(\"f1_score\",f1_score(y_pred,y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.939935064935065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[ 0  3 67] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-84e298a5fc0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2133\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2134\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1269\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[ 0  3 67] not in index'"
     ]
    }
   ],
   "source": [
    "ccc = CalibratedClassifierCV(clf)\n",
    "ccc.fit(X_train, y_train)\n",
    "print(\"score\", ccc.score(X_train, y_train))\n",
    "ccc.predict_proba(X_train[[0,3,67]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cutoff 1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0007815422964909467, 'T2Acc1t'),\n",
       " (0.0008800004798725034, 'T1Acc1t'),\n",
       " (0.0010527644607948997, 'T2Acc1n'),\n",
       " (0.001098352041538814, 'T1Acc1n'),\n",
       " (0.010518485351609442, 'COMT_Hap1_LvsMH'),\n",
       " (0.019755025057815734, 'dyslexia'),\n",
       " (0.025757682259725984, 'COMT_Hap1_recode'),\n",
       " (0.030393877314405494, 'Hebrew'),\n",
       " (0.032550540288894855, 'highschool_diploma'),\n",
       " (0.044098269624972715, 'HML_5HTT'),\n",
       " (0.04719505255416798, 'HML_NPY'),\n",
       " (0.04793751144065832, 'HL_MAOA'),\n",
       " (0.04901906678225791, 'HML_FKBP5'),\n",
       " (0.049689746652074956, 'military_exposure_unit'),\n",
       " (0.05483568510047811, 'COMT_Hap2_recode'),\n",
       " (0.06478675539024889, 'ADHD'),\n",
       " (0.08549391385194563, 'substance_use1'),\n",
       " (0.08875415570967647, 'planning2'),\n",
       " (0.09309298367719238, 'planning1'),\n",
       " (0.10527174784047409, 'age'),\n",
       " (0.11969222867900578, 'acceptance2'),\n",
       " (0.12610630582708207, 'acceptance1'),\n",
       " (0.12918312384867583, 'active_coping1'),\n",
       " (0.12998313682001117, 'instrumental_support1'),\n",
       " (0.13724756034985017, 'active_coping2'),\n",
       " (0.13887938369758043, 'positive_reframing1'),\n",
       " (0.15084403013444833, 'trauma_history8_1'),\n",
       " (0.15221080449566507, 'behavioral_disengagement2'),\n",
       " (0.1535626136290184, 'venting2'),\n",
       " (0.15896385245730096, 'denial1'),\n",
       " (0.15965369607972402, 'denial2'),\n",
       " (0.16518708642395022, 'substance_use2'),\n",
       " (0.1677069917311819, 'positive_reframing2'),\n",
       " (0.1720676557974236, 'venting1'),\n",
       " (0.17889297087689318, 'behavioral_disengagement1'),\n",
       " (0.18256837049199617, 'self_distraction1'),\n",
       " (0.1925839918361228, 'emotional_support1'),\n",
       " (0.19400572360816595, 'religion2'),\n",
       " (0.19435447507744782, 'instrumental_support2'),\n",
       " (0.2030821489911046, 'self_blame1'),\n",
       " (0.2085815490478728, 'religion1'),\n",
       " (0.2261087750852764, 'self_distraction2'),\n",
       " (0.241296249264189, 'self_blame2'),\n",
       " (0.25162266847179876, 'humor1'),\n",
       " (0.2699685938012816, 'emotional_support2'),\n",
       " (0.27011204171018055, 'humor2'),\n",
       " (0.29444531738732677, 'lot1'),\n",
       " (0.7339331059219155, 'phq1'),\n",
       " (0.7510559347588239, 'lot2'),\n",
       " (1.3921215180467492, 'phq2'),\n",
       " (1.7479150642805976, 'trait1'),\n",
       " (2.1180736454651656, 'T1bias'),\n",
       " (2.1449953793243006, 'T2bias'),\n",
       " (2.2189826350186594, 'Ashken_scale'),\n",
       " (2.2215646384008645, 'Unknown'),\n",
       " (2.2588366438131975, 'state1'),\n",
       " (2.2624275419560234, 'T1ETBE'),\n",
       " (2.3323600872078716, 'ptgi2'),\n",
       " (2.4550210263822203, 'Sephar_scale'),\n",
       " (2.467446818354033, 'cd_risc1'),\n",
       " (2.577188611409121, 'trait2'),\n",
       " (2.5793575175104153, 'PCL1'),\n",
       " (2.7021111854667494, 'state2'),\n",
       " (2.770863171907318, 'PCL2')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(np.abs(pca.components_).sum(axis=0), features), key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1\n",
    "pca_list =  zip(np.abs(pca.components_).sum(axis=0), features)\n",
    "pca_importance =[x[1] for x in pca_list if x[0] > cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pca_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1ETBE',\n",
       " 'T1bias',\n",
       " 'T2bias',\n",
       " 'state1',\n",
       " 'state2',\n",
       " 'trait1',\n",
       " 'trait2',\n",
       " 'phq2',\n",
       " 'PCL1',\n",
       " 'PCL2',\n",
       " 'cd_risc1',\n",
       " 'ptgi2',\n",
       " 'Ashken_scale',\n",
       " 'Sephar_scale',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
