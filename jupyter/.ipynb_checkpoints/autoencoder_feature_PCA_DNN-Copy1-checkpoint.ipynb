{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "import keras.metrics\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Input\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "import featuretools as ft\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "#df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"ID\" ,\"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\", \"T1ETBE\", \"T1Acc1t\",\n",
    "                         \"T1Acc1n\", \"T1bias\", \"T2Acc1t\", \"T2Acc1n\", \"T2bias\", \"state1\", \"state2\", \"trait1\",\n",
    "                         \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"PCL1\", \"PCL2\", \"cd_risc1\", \"ptgi2\",\n",
    "                         \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                         \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                         \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                         \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                         \"religion2\", \"emotional_support2\", \"instrumental_support2\",\"self_distraction2\",\n",
    "                         \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                         \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                         \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                         \"Sephar_scale\", \"Unknown\", 'terror_p1', 'terror_i1', 'mva_p1', 'mva_i1',                   \n",
    "                         'violent1', 'sexual1', 'rockets_p1', 'rockets_i1', 'trauma_history6_1',\n",
    "                        'terror_p2','terror_i2','mva_p2', 'mva_i2', 'violent2', 'sexual2', 'rockets_p2',\n",
    "                        'rockets_i2', 'trauma6t2', 'trauma8t2', 'military_exp18_1','military_exp18_t2',\n",
    "                        'commanders18','commanders20', 'commanders22', 't1bias_1_zero', 'state1_zero',\n",
    "                        'trait1_zero', 'PHQ1_zero', 'PCL1_zero', 'depression_clinical2', 'avoid_bias',\n",
    "                        'ptsd1_clini', 'avoidance_cop', 'clinical_depression15', 'avoidance_compa',\n",
    "                        'resilience_compa', 'combat_compa', 'emotional_cop1n', 'avoidance_cop2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [ \"T1ETBE\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"T2Acc1t\",\"T2Acc1n\", \"T2bias\", \"state1\", \"state2\",\n",
    "                        \"trait1\", \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"cd_risc1\", \"PCL1\", \"PCL2\"]\n",
    "categorical_features = [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\",   \"ptgi2\",\n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                    \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                    \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                    \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                    \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                    \"Sephar_scale\", \"Unknown\", 'terror_p1', 'terror_i1', 'mva_p1', 'mva_i1',                   \n",
    "                    'violent1', 'sexual1', 'rockets_p1', 'rockets_i1', 'trauma_history6_1', 'terror_p2','terror_i2',\n",
    "                    'mva_p2', 'mva_i2', 'violent2', 'sexual2', 'rockets_p2', 'rockets_i2', 'trauma6t2', 'trauma8t2',\n",
    "                    'military_exp18_1','military_exp18_t2', 'commanders18','commanders20','commanders22', \n",
    "                    't1bias_1_zero', 'state1_zero', 'trait1_zero', 'PHQ1_zero', 'PCL1_zero', 'depression_clinical2',\n",
    "                    'avoid_bias', 'ptsd1_clini', 'avoidance_cop', 'clinical_depression15', 'avoidance_compa',\n",
    "                    'resilience_compa', 'combat_compa', 'emotional_cop1n', 'avoidance_cop2', 'avoidance_cop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh=0.5, axis=1,inplace=True)\n",
    "df.dropna(thresh=0.9, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "Y = df[\"PCL_Strict3\"]\n",
    "df = df[features]\n",
    "df = df - df.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-26 15:51:50,174 featuretools.entityset - WARNING    ('Using first column as index. ', 'To change this, specify the index parameter')\n"
     ]
    }
   ],
   "source": [
    "es = ft.EntitySet(id = 'ID')\n",
    "es = es.entity_from_dataframe(entity_id='ID', dataframe = df)\n",
    "new_features, new_feature_names = ft.dfs(entityset = es, target_entity = 'ID',  max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_features\n",
    "new_feature_names = df.columns\n",
    "df[\"PCL_Strict3\"] = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[~df[\"PCL_Strict3\"].isna()][new_feature_names]\n",
    "Y = df[~df[\"PCL_Strict3\"].isna()][\"PCL_Strict3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'highschool_diploma', 'Hebrew', 'dyslexia', 'ADHD', 'T1ETBE',\n",
       "       'T1Acc1t', 'T1Acc1n', 'T1bias', 'T2Acc1t',\n",
       "       ...\n",
       "       'depression_clinical2', 'avoid_bias', 'ptsd1_clini', 'avoidance_cop',\n",
       "       'clinical_depression15', 'avoidance_compa', 'resilience_compa',\n",
       "       'combat_compa', 'emotional_cop1n', 'avoidance_cop2'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      -17.830462\n",
       "highschool_diploma       -19.521306\n",
       "Hebrew                    -3.404352\n",
       "dyslexia                   2.241160\n",
       "ADHD                      13.145059\n",
       "T1ETBE                  -319.917940\n",
       "T1Acc1t                    0.013184\n",
       "T1Acc1n                   -0.028026\n",
       "T1bias                  -361.705024\n",
       "T2Acc1t                   -0.074680\n",
       "T2Acc1n                   -0.251227\n",
       "T2bias                   773.998251\n",
       "state1                   308.648109\n",
       "state2                   334.416368\n",
       "trait1                   232.267073\n",
       "trait2                   330.670829\n",
       "lot1                      13.822629\n",
       "lot2                     -21.333296\n",
       "phq1                     260.511176\n",
       "phq2                     293.167456\n",
       "PCL1                     456.535711\n",
       "PCL2                     529.194120\n",
       "cd_risc1                   3.276339\n",
       "ptgi2                    505.905839\n",
       "active_coping1            -2.641886\n",
       "planning1                  6.594742\n",
       "positive_reframing1       -4.353581\n",
       "acceptance1               -8.403445\n",
       "humor1                   -42.223028\n",
       "religion1                 58.184950\n",
       "                            ...    \n",
       "terror_p2                  0.611967\n",
       "terror_i2                  0.314597\n",
       "mva_p2                   -25.878513\n",
       "mva_i2                     2.330916\n",
       "violent2                  -4.500453\n",
       "sexual2                   -0.398912\n",
       "rockets_p2               -21.703536\n",
       "rockets_i2                -1.056210\n",
       "trauma6t2                -27.657480\n",
       "trauma8t2                 18.780598\n",
       "military_exp18_1          41.694651\n",
       "military_exp18_t2         -7.124823\n",
       "commanders18             -48.090662\n",
       "commanders20            -128.047144\n",
       "commanders22            -312.685403\n",
       "t1bias_1_zero           -374.073073\n",
       "state1_zero              465.609674\n",
       "trait1_zero              278.775295\n",
       "PHQ1_zero                307.677090\n",
       "PCL1_zero                563.769302\n",
       "depression_clinical2       6.926564\n",
       "avoid_bias                -0.144152\n",
       "ptsd1_clini                5.775159\n",
       "avoidance_cop             68.832276\n",
       "clinical_depression15    -19.562103\n",
       "avoidance_compa          116.260199\n",
       "resilience_compa          -1.037171\n",
       "combat_compa             -83.276519\n",
       "emotional_cop1n          -31.020852\n",
       "avoidance_cop2            51.844968\n",
       "Length: 103, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[df[\"PCL_Strict3\"].isna()][new_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.05, random_state=271828, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(X_train, y_train):\n",
    "    X_train_3 = X_train[y_train==1]\n",
    "    y_train_3 = y_train[y_train==1]\n",
    "    X_train_4 = X_train[y_train==0][:20:]\n",
    "    y_train_4 = y_train[y_train==0][:20:]\n",
    "    X_train_5 = np.vstack((X_train_4, X_train_3))\n",
    "    y_train_5 =  np.hstack((y_train_4, y_train_3))\n",
    "    sm = SMOTE(random_state=27)\n",
    "    X_train_6, y_train_6 = sm.fit_sample(X_train_5, y_train_5.ravel())\n",
    "    X_train_6 = X_train_6[y_train_6==0]\n",
    "    y_train_6 = y_train_6[y_train_6==0]\n",
    "    return X_train_6, y_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi(X_train, y_train, X_test, pca):\n",
    "    \n",
    "    xxx = df[df[\"PCL_Strict3\"].isna()][new_feature_names]\n",
    "    xxx = pca.transform(xxx)\n",
    "    X_train_2 = np.vstack((X_train, xxx))\n",
    "    \n",
    "    unlabeled = df[df[\"PCL_Strict3\"].isna()]['PCL_Strict3'].fillna(-1)\n",
    "    \n",
    "    y_train_2 = np.hstack((y_train, unlabeled))\n",
    "    \n",
    "    clf = LabelSpreading(gamma=20, n_neighbors=150,alpha=0.0005,kernel='knn')\n",
    "    \n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    \n",
    "    \n",
    "    X_train = np.hstack((X_train, clf.predict(X_train).reshape(-1,1)))\n",
    "    X_test = np.hstack((X_test, clf.predict(X_test).reshape(-1,1)))\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto(X_train, X_test, pca):\n",
    "    \n",
    "    xxx = df[df[\"PCL_Strict3\"].isna()][new_feature_names]\n",
    "    xxx = pca.transform(xxx)\n",
    "    X_train_2 = np.vstack((X_train, xxx))\n",
    "\n",
    "    encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(X_train_2.shape[1],))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(X_train_2.shape[1], activation='sigmoid')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "\n",
    "    encoder = Model(input_img, encoded)\n",
    "    # create a placeholder for an encoded (32-dimensional) input\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    # create the decoder model\n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=256,\n",
    "                    shuffle=True, verbose=0)    \n",
    "\n",
    "    X_train = np.hstack((X_train, encoder.predict(X_train)))\n",
    "    X_test = np.hstack((X_test, encoder.predict(X_test)))\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_layers 3 \n",
      "first_layer 75 \n",
      "each_layer 12 \n",
      "num_smote 0.95 \n",
      "loops 50 \n",
      "class_weight {1: 0.51, 0: 0.49}\n",
      "\tscores f1 0.23076923076923078\n",
      "\tscores p 0.23076923076923078\n",
      "\tscores r 0.23076923076923078\n",
      "\tscores f1 0.32432432432432434\n",
      "\tscores p 0.46153846153846156\n",
      "\tscores r 0.25\n",
      "\tscores f1 0.1714285714285714\n",
      "\tscores p 0.25\n",
      "\tscores r 0.13043478260869565\n",
      "mean scores f1 0.24217404217404218\n",
      "mean scores p 0.3141025641025641\n",
      "mean scores r 0.20373467112597546\n",
      "\n",
      "\n",
      "num_layers 3 \n",
      "first_layer 75 \n",
      "each_layer 12 \n",
      "num_smote 0.95 \n",
      "loops 50 \n",
      "class_weight {1: 0.55, 0: 0.45}\n",
      "\tscores f1 0.18181818181818185\n",
      "\tscores p 0.15384615384615385\n",
      "\tscores r 0.2222222222222222\n",
      "\tscores f1 0.21428571428571427\n",
      "\tscores p 0.23076923076923078\n",
      "\tscores r 0.2\n",
      "\tscores f1 0.0\n",
      "\tscores p 0.0\n",
      "\tscores r 0.0\n",
      "mean scores f1 0.13203463203463203\n",
      "mean scores p 0.12820512820512822\n",
      "mean scores r 0.14074074074074075\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "cvscores = []\n",
    "y_train_2 = np.array(y_train_2)\n",
    "X_train_2 = np.array(X_train_2)\n",
    "\n",
    "for class_weight in [{1:0.51, 0:0.49}, {1:0.55, 0:0.45}]:\n",
    "    for num_smote in [0.95]:\n",
    "        for num_layers in [3]:\n",
    "            for first_layer in [75]:\n",
    "                for loops in [50]:\n",
    "                    for each_layer in [12]:\n",
    "                        num_layers = num_layers\n",
    "                        first_layer = first_layer\n",
    "                        each_layer = each_layer\n",
    "                        num_smote = num_smote\n",
    "                        n_pca = 0.99\n",
    "                        loops = loops\n",
    "                        scores_f = []\n",
    "                        scores_p = []\n",
    "                        scores_r = []\n",
    "                        print(\"\\n\\nnum_layers\", num_layers, \"\\nfirst_layer\", first_layer, \n",
    "                                  \"\\neach_layer\", each_layer, \"\\nnum_smote\", num_smote,\n",
    "                              \"\\nloops\", loops, \"\\nclass_weight\", class_weight)\n",
    "                        for train, test in kfold.split(X_train_2, y_train_2):\n",
    "                            \n",
    "                            pca = PCA(n_components = n_pca)\n",
    "                            X_train_3 = pca.fit_transform(X_train_2[train])\n",
    "                            X_test_3 = pca.transform(X_train_2[test])\n",
    "                            y_train_3 = y_train_2[train]\n",
    "                            x, y = create_data(X_train_3, y_train_3)\n",
    "                            created_X = x\n",
    "                            created_y = y\n",
    "                            for i in range(loops):\n",
    "                                X_train_3, y_train_3 = shuffle(X_train_3, y_train_3)\n",
    "                                x, y = create_data(X_train_3, y_train_3)\n",
    "                                created_X = np.vstack((created_X, x))\n",
    "                                created_y = np.hstack((created_y, y))\n",
    "                            X_train_3 = np.vstack([created_X, X_train_3])\n",
    "                            y_train_3 =  np.hstack([created_y, y_train_3])\n",
    "\n",
    "                            sm = SMOTE(random_state=27)\n",
    "                            X_train_res, y_train_res = sm.fit_sample(X_train_3, y_train_3.ravel())\n",
    "\n",
    "\n",
    "                            n_cols = X_train_res.shape[1]\n",
    "\n",
    "                            input_img = Input(shape=(n_cols,))\n",
    "\n",
    "                            x = Dense(n_cols, activation='relu')(input_img)\n",
    "\n",
    "                            encoded = Dense(n_cols//2, activation='relu')(x)\n",
    "                            encoded = Dense(n_cols//4, activation='relu')(encoded)\n",
    "\n",
    "                            y = Dense(n_cols//8, activation='relu')(x)\n",
    "\n",
    "                            decoded = Dense(n_cols//4, activation='relu')(y)\n",
    "                            decoded = Dense(n_cols//2, activation='relu')(decoded)\n",
    "\n",
    "                            z = Dense(n_cols, activation='sigmoid')(decoded)\n",
    "                            model = Model(input_img, z)\n",
    "\n",
    "                            model.compile(optimizer='adadelta', loss='mse') # reporting the accuracy\n",
    "\n",
    "                            xxx = df[df[\"PCL_Strict3\"].isna()][new_feature_names]\n",
    "                            xxx = pca.transform(xxx)\n",
    "                            X_train_res_2 = np.vstack((X_train_res, xxx))\n",
    "\n",
    "                            \n",
    "                            model.fit(X_train_res_2, X_train_res_2,\n",
    "                                  epochs=1000,\n",
    "                                  batch_size=128,\n",
    "                                  verbose=0)\n",
    "\n",
    "                            mid = Model(input_img, y)\n",
    "                            #reduced_representation =mid.predict(X_train_2[test])\n",
    "\n",
    "                            out = Dense(1, activation='sigmoid')(y)\n",
    "                            reduced = Model(input_img, out)\n",
    "                            reduced.compile(loss='binary_crossentropy',\n",
    "                                      optimizer='adam', \n",
    "                                      metrics=['accuracy']) \n",
    "\n",
    "                            reduced.fit(X_train_res, y_train_res,\n",
    "                                  epochs=1000,\n",
    "                                  batch_size=128,\n",
    "                                  verbose=0, class_weight=class_weight)\n",
    "                            \n",
    "                            y_pred =  reduced.predict(X_test_3)\n",
    "                        \n",
    "                            \n",
    "                            y_pred = (y_pred) > 0.5\n",
    "                            \n",
    "                            s_f = f1_score(y_pred,y_train_2[test])\n",
    "                            s_p = precision_score(y_pred,y_train_2[test])\n",
    "                            s_r = recall_score(y_pred,y_train_2[test])\n",
    "                            print(\"\\tscores f1\", (s_f))\n",
    "                            print(\"\\tscores p\", (s_p))\n",
    "                            print(\"\\tscores r\", (s_r))\n",
    "                            scores_f.append(s_f)\n",
    "                            scores_p.append(s_p)\n",
    "                            scores_r.append(s_r)\n",
    "\n",
    "                        print(\"mean scores f1\", np.mean(scores_f))\n",
    "                        print(\"mean scores p\", np.mean(scores_p))\n",
    "                        print(\"mean scores r\", np.mean(scores_r))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
