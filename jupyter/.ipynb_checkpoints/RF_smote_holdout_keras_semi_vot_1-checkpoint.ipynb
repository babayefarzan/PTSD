{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "import keras.metrics\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\", \"T1ETBE\", \"T1Acc1t\",\n",
    "                         \"T1Acc1n\", \"T1bias\", \"T2Acc1t\", \"T2Acc1n\", \"T2bias\", \"state1\", \"state2\", \"trait1\",\n",
    "                         \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"PCL1\", \"PCL2\", \"cd_risc1\", \"ptgi2\",\n",
    "                         \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                         \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                         \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                         \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                         \"religion2\", \"emotional_support2\", \"instrumental_support2\",\"self_distraction2\",\n",
    "                         \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                         \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                         \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                         \"Sephar_scale\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [ \"T1ETBE\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"T2Acc1t\",\"T2Acc1n\", \"T2bias\", \"state1\", \"state2\",\n",
    "                        \"trait1\", \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"cd_risc1\", \"PCL1\", \"PCL2\"]\n",
    "categorical_features = [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\",   \"ptgi2\",\n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                    \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                    \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                    \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                    \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                    \"Sephar_scale\", \"Unknown\"]\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "\n",
    "X = df[features]\n",
    "X = X - X.mean()\n",
    "Y = df[\"PCL_Strict3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"interaction_1\"] = X[\"T1Acc1t\"] * X[\"T2Acc1n\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_2\"] = X[\"T1Acc1n\"] * X[\"T2Acc1t\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_3\"] = X[\"highschool_diploma\"] * X[\"military_exposure_unit\"] * X['PCL1']\n",
    "X[\"interaction_4\"] = X[\"T1ETBE\"] * X[\"military_exposure_unit\"] * X['HML_5HTT']\n",
    "\n",
    "# for i, feature in enumerate(features):\n",
    "#     for interation in features[i::]:\n",
    "#         X[f\"interaction_{feature}_{interation}\"] = X[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, random_state=271828, stratify=y_train)\n",
    "#X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_2, y_train_2, test_size = 0.1, random_state=271828, stratify=y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(X_train, y_train):\n",
    "    X_train_3 = X_train[y_train==1]\n",
    "    y_train_3 = y_train[y_train==1]\n",
    "    X_train_4 = X_train[y_train==0][:20:]\n",
    "    y_train_4 = y_train[y_train==0][:20:]\n",
    "    X_train_5 = np.vstack((X_train_4, X_train_3))\n",
    "    y_train_5 =  np.hstack((y_train_4, y_train_3))\n",
    "    sm = SMOTE(random_state=27)\n",
    "    X_train_6, y_train_6 = sm.fit_sample(X_train_5, y_train_5.ravel())\n",
    "    X_train_6 = X_train_6[y_train_6==0]\n",
    "    y_train_6 = y_train_6[y_train_6==0]\n",
    "    return X_train_6, y_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_layers 4 \n",
      "first_layer 75 \n",
      "each_layer 4 \n",
      "num_smote 0.95 \n",
      "loops 1\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvscores = []\n",
    "y_train_2 = np.array(y_train_2)\n",
    "X_train_2 = np.array(X_train_2)\n",
    "\n",
    "for num_smote in [0.95, 0.85]:\n",
    "    for num_layers in [4]:\n",
    "        for first_layer in [75, 25]:\n",
    "            for loops in [1]:\n",
    "                for each_layer in [4, 20]:\n",
    "                    num_layers = num_layers\n",
    "                    first_layer = first_layer\n",
    "                    each_layer = each_layer\n",
    "                    num_smote = num_smote\n",
    "                    loops = loops\n",
    "                    scores = []\n",
    "                    print(\"\\n\\nnum_layers\", num_layers, \"\\nfirst_layer\", first_layer, \n",
    "                              \"\\neach_layer\", each_layer, \"\\nnum_smote\", num_smote, \"\\nloops\", loops)\n",
    "                    for train, test in kfold.split(X_train_2, y_train_2):\n",
    "\n",
    "                        x, y = create_data(X_train_2[train], y_train_2[train])\n",
    "                        created_X = x\n",
    "                        created_y = y\n",
    "                        for i in range(loops):\n",
    "                            X_train_3, y_train_3 = shuffle(X_train_2[train], y_train_2[train])\n",
    "                            x, y = create_data(X_train_3, y_train_3)\n",
    "                            created_X = np.vstack((created_X, x))\n",
    "                            created_y = np.hstack((created_y, y))\n",
    "                        X_train_3 = np.vstack([created_X, X_train_3])\n",
    "                        y_train_3 =  np.hstack([created_y, y_train_3])\n",
    "\n",
    "                        sm = SMOTE(random_state=27)\n",
    "                        X_train_res, y_train_res = sm.fit_sample(X_train_3, y_train_3.ravel())\n",
    "\n",
    "                        pca = PCA(n_components = 0.99)\n",
    "                        X_train_res = pca.fit_transform(X_train_res)\n",
    "                        X_test_2 = pca.transform(X_train_2[test])\n",
    "                      # create model\n",
    "                        n_cols = X_train_res.shape[1]\n",
    "                        model = Sequential()\n",
    "                        model.add(Dense(first_layer, activation='elu', input_dim = n_cols))\n",
    "                        model.add(Dropout(0.5))\n",
    "\n",
    "                        for i in range(num_layers):\n",
    "                            model.add(Dense(each_layer, activation='elu'))\n",
    "                            model.add(Dropout(0.5))\n",
    "\n",
    "                        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                        model.compile(optimizer='adam', \n",
    "                                      loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "                        # Fit the model\n",
    "                        model.fit(X_train_res, y_train_res, epochs = 250, validation_split = .1, verbose=0)\n",
    "                        # evaluate the model\n",
    "                        y_pred =  model.predict(X_test_2)\n",
    "                        y_pred = y_pred>0.5\n",
    "\n",
    "                        s = f1_score(y_pred,y_train_2[test])\n",
    "                        #print(s)\n",
    "                        scores.append(s)\n",
    "                    print(\"mean scores\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
