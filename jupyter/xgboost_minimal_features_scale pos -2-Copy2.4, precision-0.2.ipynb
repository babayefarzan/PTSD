{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "# import keras.metrics\n",
    "# from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "# from keras.models import Sequential\n",
    "# from keras.callbacks import History \n",
    "# from keras.utils import plot_model\n",
    "# from keras.optimizers import SGD\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"T1bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_features = [ \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"state1\", \"trait1\", \"lot1\", \"phq1\",\n",
    "                      \"cd_risc1\", \"PCL1\", \"PCL2\", \"trauma_history8_1\"]\n",
    "categorical_features = [\"age\", \"highschool_diploma\",  \"dyslexia\", \"ADHD\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"phq1\", \n",
    "                        \"lot1\", \"trait1\", \"state1\",  \"PCL_Broad1\", \"PCL_Strict1\", \"active_coping1\",\n",
    "                        \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\", \"religion1\", \n",
    "                        \"emotional_support1\",\"instrumental_support1\", \"self_distraction1\", \"denial1\", \n",
    "                        \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\"]\n",
    "\n",
    "#df['bad_features'] = (df > df.mean())[bad_features].sum(axis=1)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# X = ss.fit_transform(X)\n",
    "\n",
    "\n",
    "Y = df[\"PCL_Strict3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, random_state=271828, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =  Pipeline([\n",
    "    \n",
    "                ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [\n",
    "    {\n",
    "       # 'pca__n_components': [0.9],\n",
    "        'classifier__min_child_weight': [1],\n",
    "        'classifier__gamma': [0],\n",
    "        'classifier__subsample': [0.9],\n",
    "        'classifier__colsample_bytree': [0.7],\n",
    "        'classifier__max_depth': [4, 2],\n",
    "  #      'classifier__reg_alpha' : [0.2, 0.9],\n",
    "   #     'classifier__reg_lambda' : [0.5, 0.2, 0.9],\n",
    "        'classifier__scale_pos_weight' : [1, 2, 0.5],\n",
    "    'classifier__learning_rate': [0.05, 0.1], #so called `eta` value\n",
    "              'classifier__n_estimators': [300,100], #number of trees, change it to 1000 for better results\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'classifier__min_child_weight': [1], 'classifier__gamma': [0], 'classifier__subsample': [0.9], 'classifier__colsample_bytree': [0.7], 'classifier__max_depth': [4, 2], 'classifier__scale_pos_weight': [1, 2, 0.5], 'classifier__learning_rate': [0.05, 0.1], 'classifier__n_estimators': [300, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "gs = GridSearchCV(pipe, params_grid, cv=kfold, scoring='precision')\n",
    "gs.fit(X_train_2, y_train_2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.7,\n",
       " 'classifier__gamma': 0,\n",
       " 'classifier__learning_rate': 0.05,\n",
       " 'classifier__max_depth': 4,\n",
       " 'classifier__min_child_weight': 1,\n",
       " 'classifier__n_estimators': 300,\n",
       " 'classifier__scale_pos_weight': 1,\n",
       " 'classifier__subsample': 0.9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
