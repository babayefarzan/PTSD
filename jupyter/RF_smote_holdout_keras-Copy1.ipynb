{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "import keras.metrics\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\", \"T1ETBE\", \"T1Acc1t\",\n",
    "                         \"T1Acc1n\", \"T1bias\", \"T2Acc1t\", \"T2Acc1n\", \"T2bias\", \"state1\", \"state2\", \"trait1\",\n",
    "                         \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"PCL1\", \"PCL2\", \"cd_risc1\", \"ptgi2\",\n",
    "                         \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                         \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                         \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                         \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                         \"religion2\", \"emotional_support2\", \"instrumental_support2\",\"self_distraction2\",\n",
    "                         \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                         \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                         \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                         \"Sephar_scale\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [ \"T1ETBE\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"T2Acc1t\",\"T2Acc1n\", \"T2bias\", \"state1\", \"state2\",\n",
    "                        \"trait1\", \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"cd_risc1\", \"PCL1\", \"PCL2\"]\n",
    "categorical_features = [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\",   \"ptgi2\",\n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                    \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                    \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                    \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                    \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                    \"Sephar_scale\", \"Unknown\"]\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "\n",
    "X = df[features]\n",
    "X = X - X.mean()\n",
    "Y = df[\"PCL_Strict3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"interaction_1\"] = X[\"T1Acc1t\"] * X[\"T2Acc1n\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_2\"] = X[\"T1Acc1n\"] * X[\"T2Acc1t\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_3\"] = X[\"highschool_diploma\"] * X[\"military_exposure_unit\"] * X['PCL1']\n",
    "X[\"interaction_4\"] = X[\"T1ETBE\"] * X[\"military_exposure_unit\"] * X['HML_5HTT']\n",
    "\n",
    "# for i, feature in enumerate(features):\n",
    "#     for interation in features[i::]:\n",
    "#         X[f\"interaction_{feature}_{interation}\"] = X[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, random_state=271828, stratify=y_train)\n",
    "#X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_2, y_train_2, test_size = 0.1, random_state=271828, stratify=y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(X_train, y_train):\n",
    "    X_train_3 = X_train[y_train==1]\n",
    "    y_train_3 = y_train[y_train==1]\n",
    "    X_train_4 = X_train[y_train==0][:20:]\n",
    "    y_train_4 = y_train[y_train==0][:20:]\n",
    "    X_train_5 = np.vstack((X_train_4, X_train_3))\n",
    "    y_train_5 =  np.hstack((y_train_4, y_train_3))\n",
    "    sm = SMOTE(random_state=27)\n",
    "    X_train_6, y_train_6 = sm.fit_sample(X_train_5, y_train_5.ravel())\n",
    "    X_train_6 = X_train_6[y_train_6==0]\n",
    "    y_train_6 = y_train_6[y_train_6==0]\n",
    "    return X_train_6, y_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.145124716553288\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.13107606679035252\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "mean scores 0.14682539682539683\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "mean scores 0.18594104308390022\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.14682539682539683\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.08333333333333334\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "mean scores 0.03571428571428571\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "mean scores 0.11507936507936509\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.28596165739022883\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 10 \n",
      "num_smote 1 \n",
      "loops 3\n",
      "mean scores 0.11746031746031746\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n",
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2 \n",
      "first_layer 75 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2fb7e952dbd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                     \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1263\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=7, shuffle=True)\n",
    "cvscores = []\n",
    "y_train_2 = np.array(y_train_2)\n",
    "X_train_2 = np.array(X_train_2)\n",
    "\n",
    "for num_layers in [1,2,4]:\n",
    "    for first_layer in [75, 25]:\n",
    "        for loops in [3, 20]:\n",
    "            for each_layer in [5, 10]:\n",
    "                num_layers = num_layers\n",
    "                first_layer = first_layer\n",
    "                each_layer = each_layer\n",
    "                num_smote = 1\n",
    "                loops = loops\n",
    "                scores = []\n",
    "                for train, test in kfold.split(X_train_2, y_train_2):\n",
    "                    print(\"num_layers\", num_layers, \"\\nfirst_layer\", first_layer, \n",
    "                          \"\\neach_layer\", each_layer, \"\\nnum_smote\", num_smote, \"\\nloops\", loops)\n",
    "                    x, y = create_data(X_train_2[train], y_train_2[train])\n",
    "                    created_X = x\n",
    "                    created_y = y\n",
    "                    for i in range(loops):\n",
    "                        X_train_3, y_train_3 = shuffle(X_train_2[train], y_train_2[train])\n",
    "                        x, y = create_data(X_train_3, y_train_3)\n",
    "                        created_X = np.vstack((created_X, x))\n",
    "                        created_y = np.hstack((created_y, y))\n",
    "                    X_train_3 = np.vstack([created_X, X_train_3])\n",
    "                    y_train_3 =  np.hstack([created_y, y_train_3])\n",
    "\n",
    "                    sm = SMOTE(random_state=27)\n",
    "                    X_train_res, y_train_res = sm.fit_sample(X_train_3, y_train_3.ravel())\n",
    "\n",
    "                  # create model\n",
    "                    n_cols = X_train_res.shape[1]\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(first_layer, activation='elu', input_dim = n_cols))\n",
    "                    model.add(Dropout(0.5))\n",
    "\n",
    "                    for i in range(num_layers):\n",
    "                        model.add(Dense(each_layer, activation='elu'))\n",
    "                        model.add(Dropout(0.5))\n",
    "\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                    model.compile(optimizer='adam', \n",
    "                                  loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "                    # Fit the model\n",
    "                    model.fit(X_train_res, y_train_res, epochs = 250, validation_split = .1, verbose=0)\n",
    "                    # evaluate the model\n",
    "                    y_pred =  model.predict(X_train_2[test])\n",
    "                    y_pred = y_pred>0.5\n",
    "\n",
    "                    s = f1_score(y_pred,y_train_2[test])\n",
    "                    #print(s)\n",
    "                    scores.append(s)\n",
    "                print(\"mean scores\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
