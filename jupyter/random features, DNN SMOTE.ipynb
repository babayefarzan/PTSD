{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "import keras.metrics\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"highschool_diploma\",  \"dyslexia\", \"ADHD\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"phq1\", \"lot1\", \"trait1\",\n",
    "               \"state1\", \"PCL1\",  \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\", \n",
    "                 \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                 \"religion1\", \"emotional_support1\",\"instrumental_support1\", \"self_distraction1\", \"denial1\", \n",
    "               \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\", \"planning2\",\n",
    "                \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\", \"instrumental_support2\", \n",
    "                 \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                 \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Ranked\", \"COMT_Hap1_recode\", \n",
    "               \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\", \"Sephar_scale\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['behavioral_disengagement1', 'PCL_Strict2', 'planning2', 'self_blame1', 'T1bias', 'trait2', 'Ashken_scale', 'PCL2', 'T1Acc1n', 'denial2', 'self_distraction2', 'lot1', 'state1', 'instrumental_support1']\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n",
      "mean precision scores 0.19421768707482995\n",
      "mean recall scores 0.2523809523809524\n",
      "mean f1 scores 0.2159792588364017\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 2} \n",
      "num_smote 1\n",
      "mean precision scores 0.17104585055712876\n",
      "mean recall scores 0.5619047619047619\n",
      "mean f1 scores 0.26084941477226536\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n",
      "mean precision scores 0.13667509164403577\n",
      "mean recall scores 0.43809523809523815\n",
      "mean f1 scores 0.1934010319103487\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "class_weight {1: 1, 0: 2} \n",
      "num_smote 1\n",
      "mean precision scores 0.20484693877551022\n",
      "mean recall scores 0.6047619047619047\n",
      "mean f1 scores 0.29876621977462314\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 0 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n",
      "mean precision scores 0.2543192102015631\n",
      "mean recall scores 0.41428571428571426\n",
      "mean f1 scores 0.3031380899801953\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 0 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 2} \n",
      "num_smote 1\n",
      "mean precision scores 0.18953702938665343\n",
      "mean recall scores 0.6714285714285715\n",
      "mean f1 scores 0.2925722939571278\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 0 \n",
      "first_layer 25 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n",
      "mean precision scores 0.2095285666714238\n",
      "mean recall scores 0.5285714285714286\n",
      "mean f1 scores 0.28568636181418133\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 0 \n",
      "first_layer 25 \n",
      "class_weight {1: 1, 0: 2} \n",
      "num_smote 1\n",
      "mean precision scores 0.1487817737817738\n",
      "mean recall scores 0.5\n",
      "mean f1 scores 0.22290355536153855\n",
      "\n",
      "_______________________\n",
      "\n",
      "['positive_reframing1', 'emotional_support2', 'positive_reframing2']\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean precision scores 0.0\n",
      "mean recall scores 0.0\n",
      "mean f1 scores 0.0\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 1 \n",
      "first_layer 75 \n",
      "class_weight {1: 1, 0: 2} \n",
      "num_smote 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean precision scores 0.0\n",
      "mean recall scores 0.0\n",
      "mean f1 scores 0.0\n",
      "\n",
      "_______________________\n",
      "\n",
      "num_layers 1 \n",
      "first_layer 25 \n",
      "class_weight {1: 1, 0: 10} \n",
      "num_smote 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_features = [\"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"phq1\", \"lot1\", \"trait1\",\n",
    "               \"state1\", \"PCL1\",  \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\", \n",
    "                 \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                 \"religion1\", \"emotional_support1\",\"instrumental_support1\", \"self_distraction1\", \"denial1\", \n",
    "               \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\", \"planning2\",\n",
    "                \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\", \"instrumental_support2\", \n",
    "                 \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                 \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Ranked\", \"COMT_Hap1_recode\", \n",
    "               \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\"]\n",
    "\n",
    "categorical_features = [\"age\", \"highschool_diploma\",  \"dyslexia\", \"ADHD\",\"Ashken_scale\", \"Sephar_scale\", \"Unknown\"]\n",
    "\n",
    "# #df['bad_features'] = (df > df.mean())[bad_features].sum(axis=1)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    # how many features to take \n",
    "    amount_features = random.randint(3, 16)\n",
    "\n",
    "    #which features to take\n",
    "    random.shuffle(features)\n",
    "    X = df[features[:amount_features]]\n",
    "\n",
    "    print(features[:amount_features])\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "\n",
    "\n",
    "    Y = df[\"PCL_Strict3\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, random_state=271828, stratify=y_train)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=7, shuffle=True)\n",
    "    cvscores = []\n",
    "    y_train_2 = np.array(y_train_2)\n",
    "    X_train_2 = np.array(X_train_2)\n",
    "\n",
    "    for num_layers in [1, 0]:\n",
    "        for first_layer in [75, 25]:\n",
    "            for each_layer in [10]:\n",
    "                for class_weight in [{1:1, 0:10}, {1:1, 0:2}]:\n",
    "                    num_layers = num_layers\n",
    "                    first_layer = first_layer\n",
    "                    each_layer = 10\n",
    "                    num_smote = 1\n",
    "                    loops = 0\n",
    "                    scores_f = []\n",
    "                    scores_r = []\n",
    "                    scores_p = []\n",
    "                    print(\"num_layers\", num_layers, \"\\nfirst_layer\", first_layer, \n",
    "                              \"\\nclass_weight\", class_weight, \"\\nnum_smote\", num_smote)\n",
    "                    for train, test in kfold.split(X_train_2, y_train_2):\n",
    "\n",
    "                        sm = SMOTE(k_neighbors= 10)\n",
    "                        X_train_res = X_train_2[train]\n",
    "                        y_train_res = y_train_2[train]\n",
    "\n",
    "                        X_train_res, y_train_res = sm.fit_sample(X_train_res, y_train_res.ravel())\n",
    "\n",
    "                      # create model\n",
    "                        n_cols = X_train_res.shape[1]\n",
    "                        model = Sequential()\n",
    "                        model.add(Dense(first_layer, activation='elu', input_dim = n_cols))\n",
    "                        model.add(Dropout(0.5))\n",
    "\n",
    "                        for i in range(num_layers):\n",
    "                            model.add(Dense(each_layer, activation='elu'))\n",
    "                            model.add(Dropout(0.5))\n",
    "\n",
    "                        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                        model.compile(optimizer='adam', \n",
    "                                      loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "                        # Fit the model\n",
    "                        callbacks = [EarlyStopping(monitor='val_loss', patience=0)]\n",
    "                        model.fit(X_train_res, y_train_res, epochs = 400, validation_split = .1, verbose=0, callbacks=callbacks, class_weight = class_weight)\n",
    "                        # evaluate the model\n",
    "                        y_pred =  model.predict(X_train_2[test])\n",
    "                        y_train_pred =  model.predict(X_train_2[train])\n",
    "                        y_pred = y_pred>0.5\n",
    "                        s_f = f1_score(y_train_2[test], y_pred)\n",
    "                        s_p = precision_score(y_train_2[test], y_pred)\n",
    "                        s_r = recall_score(y_train_2[test], y_pred)\n",
    "                        #print(\"\\tscores f1\", (s_f))\n",
    "                        #print(\"\\tscores p\", (s_p))\n",
    "                        #print(\"\\tscores r\", (s_r))\n",
    "                        s = f1_score(y_pred,y_train_2[test])\n",
    "                        #print(s)\n",
    "\n",
    "                        scores_f.append(s_f)\n",
    "                        scores_p.append(s_p)\n",
    "                        scores_r.append(s_r)\n",
    "\n",
    "\n",
    "                        #y_train_pred = (y_train_pred > 0.5)\n",
    "                        #train_s_f = f1_score(y_train_2[train], y_train_pred)\n",
    "                        #train_s_p = precision_score(y_train_2[train], y_train_pred)\n",
    "                        #train_s_r = recall_score(y_train_2[train], y_train_pred)\n",
    "                        #print(\"\\tscores f1 train\", (train_s_f))\n",
    "                        #print(\"\\tscores p train\", (train_s_p))\n",
    "                        #print(\"\\tscores r train\", (train_s_r))\n",
    "                    print(\"mean precision scores\", np.mean(scores_p))\n",
    "                    print(\"mean recall scores\", np.mean(scores_r))\n",
    "                    print(\"mean f1 scores\", np.mean(scores_f))\n",
    "                    print (\"\\n_______________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
