{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras\n",
    "import keras.metrics\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df = df[~df[\"PCL_Strict3\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\", \"T1ETBE\", \"T1Acc1t\",\n",
    "                         \"T1Acc1n\", \"T1bias\", \"T2Acc1t\", \"T2Acc1n\", \"T2bias\", \"state1\", \"state2\", \"trait1\",\n",
    "                         \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"PCL1\", \"PCL2\", \"cd_risc1\", \"ptgi2\",\n",
    "                         \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                         \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                         \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                         \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                         \"religion2\", \"emotional_support2\", \"instrumental_support2\",\"self_distraction2\",\n",
    "                         \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                         \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                         \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                         \"Sephar_scale\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [ \"T1ETBE\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"T2Acc1t\",\"T2Acc1n\", \"T2bias\", \"state1\", \"state2\",\n",
    "                        \"trait1\", \"trait2\", \"lot1\", \"lot2\", \"phq1\", \"phq2\", \"cd_risc1\", \"PCL1\", \"PCL2\"]\n",
    "categorical_features = [ \"age\", \"highschool_diploma\", \"Hebrew\", \"dyslexia\", \"ADHD\",   \"ptgi2\",\n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                    \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\n",
    "                    \"denial1\", \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "                    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "                    \"trauma_history8_1\", \"military_exposure_unit\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\",\n",
    "                    \"COMT_Hap1_recode\", \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", \"Ashken_scale\",\n",
    "                    \"Sephar_scale\", \"Unknown\"]\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df[numerical_features] = imp.fit_transform(df[numerical_features])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df[categorical_features] = imp.fit_transform(df[categorical_features])\n",
    "\n",
    "X = df[features]\n",
    "X = X - X.mean()\n",
    "Y = df[\"PCL_Strict3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"interaction_1\"] = X[\"T1Acc1t\"] * X[\"T2Acc1n\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_2\"] = X[\"T1Acc1n\"] * X[\"T2Acc1t\"] * X[\"military_exposure_unit\"]\n",
    "X[\"interaction_3\"] = X[\"highschool_diploma\"] * X[\"military_exposure_unit\"] * X['PCL1']\n",
    "X[\"interaction_4\"] = X[\"T1ETBE\"] * X[\"military_exposure_unit\"] * X['HML_5HTT']\n",
    "\n",
    "# for i, feature in enumerate(features):\n",
    "#     for interation in features[i::]:\n",
    "#         X[f\"interaction_{feature}_{interation}\"] = X[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=271828, stratify=Y)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, random_state=271828, stratify=y_train)\n",
    "#X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_2, y_train_2, test_size = 0.1, random_state=271828, stratify=y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(X_train, y_train):\n",
    "    X_train_3 = X_train[y_train==1]\n",
    "    y_train_3 = y_train[y_train==1]\n",
    "    X_train_4 = X_train[y_train==0][:20:]\n",
    "    y_train_4 = y_train[y_train==0][:20:]\n",
    "    X_train_5 = np.vstack((X_train_4, X_train_3))\n",
    "    y_train_5 =  np.hstack((y_train_4, y_train_3))\n",
    "    sm = SMOTE(random_state=27)\n",
    "    X_train_6, y_train_6 = sm.fit_sample(X_train_5, y_train_5.ravel())\n",
    "    X_train_6 = X_train_6[y_train_6==0]\n",
    "    y_train_6 = y_train_6[y_train_6==0]\n",
    "    return X_train_6, y_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = create_data(X_train_3, y_train_3)\n",
    "created_X = x\n",
    "created_y = y\n",
    "for i in range(10):\n",
    "    X_train_3, y_train_3 = shuffle(X_train_3, y_train_3)\n",
    "    x, y = create_data(X_train_3, y_train_3)\n",
    "    created_X = np.vstack((created_X, x))\n",
    "    created_y = np.hstack((created_y, y))\n",
    "X_train_3 = np.vstack([created_X, X_train_3])\n",
    "y_train_3 =  np.hstack([created_y, y_train_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=27)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_3, y_train_3.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (66,68) (2148,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-d92c98a4b631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_test_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (66,68) (2148,) "
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 0.99)\n",
    "X_train_res = pca.fit_transform(X_train_res)\n",
    "X_test_2 = pca.transform(X_test_2)\n",
    "X_test_3 = pca.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_cols = X_train_res.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='elu', input_dim = n_cols))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy')\n",
    "\n",
    "model.fit(X_train_res, y_train_res, epochs = 400, validation_split = .1)\n",
    "y_pred =  model.predict(X_test_3)\n",
    "y_pred = y_pred>0.5\n",
    "print(f1_score(y_pred,y_test_3))\n",
    "\n",
    "y_pred =  model.predict(X_test_2)\n",
    "y_pred = y_pred>0.5\n",
    "print(f1_score(y_pred,y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.25\n",
      "mean scores 0.07142857142857142\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.4444444444444444\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.3636363636363636\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.5714285714285715\n",
      "mean scores 0.19707276850133995\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.5\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.4444444444444445\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "mean scores 0.20634920634920634\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.2\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "mean scores 0.0642857142857143\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.33333333333333337\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.5714285714285715\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.22222222222222224\n",
      "mean scores 0.16099773242630389\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.22222222222222224\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.28571428571428575\n",
      "num_layers 3 \n",
      "first_layer 62 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 46\n",
      "0.28571428571428575\n",
      "mean scores 0.14909297052154197\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.20000000000000004\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.5\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.4000000000000001\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 7 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "mean scores 0.15714285714285717\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.25\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.5714285714285715\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.20000000000000004\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.28571428571428575\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 11 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.28571428571428575\n",
      "mean scores 0.2275510204081633\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.4\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.28571428571428575\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n",
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "num_layers 3 \n",
      "first_layer 97 \n",
      "each_layer 5 \n",
      "num_smote 1 \n",
      "loops 23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6930d6e152c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=7, shuffle=True)\n",
    "cvscores = []\n",
    "y_train_2 = np.array(y_train_2)\n",
    "X_train_2 = np.array(X_train_2)\n",
    "\n",
    "for first_layer in [62, 97, 25]:\n",
    "    for loops in [23, 46]:\n",
    "        for each_layer in [7, 11, 5]:\n",
    "            num_layers = 3\n",
    "            first_layer = first_layer\n",
    "            each_layer = each_layer\n",
    "            num_smote = 1\n",
    "            loops = loops\n",
    "            scores = []\n",
    "            for train, test in kfold.split(X_train_2, y_train_2):\n",
    "                print(\"num_layers\", num_layers, \"\\nfirst_layer\", first_layer, \n",
    "                      \"\\neach_layer\", each_layer, \"\\nnum_smote\", num_smote, \"\\nloops\", loops)\n",
    "                x, y = create_data(X_train_2[train], y_train_2[train])\n",
    "                created_X = x\n",
    "                created_y = y\n",
    "                for i in range(loops):\n",
    "                    X_train_3, y_train_3 = shuffle(X_train_2[train], y_train_2[train])\n",
    "                    x, y = create_data(X_train_3, y_train_3)\n",
    "                    created_X = np.vstack((created_X, x))\n",
    "                    created_y = np.hstack((created_y, y))\n",
    "                X_train_3 = np.vstack([created_X, X_train_3])\n",
    "                y_train_3 =  np.hstack([created_y, y_train_3])\n",
    "\n",
    "                sm = SMOTE(random_state=27)\n",
    "                X_train_res, y_train_res = sm.fit_sample(X_train_3, y_train_3.ravel())\n",
    "\n",
    "              # create model\n",
    "                n_cols = X_train_res.shape[1]\n",
    "                model = Sequential()\n",
    "                model.add(Dense(first_layer, activation='elu', input_dim = n_cols))\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "                for i in range(num_layers):\n",
    "                    model.add(Dense(each_layer, activation='elu'))\n",
    "                    model.add(Dropout(0.5))\n",
    "\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                model.compile(optimizer='adam', \n",
    "                              loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "                # Fit the model\n",
    "                model.fit(X_train_res, y_train_res, epochs = 250, validation_split = .1, verbose=0)\n",
    "                # evaluate the model\n",
    "                y_pred =  model.predict(X_train_2[test])\n",
    "                y_pred = y_pred>0.5\n",
    "                \n",
    "                s = f1_score(y_pred,y_train_2[test])\n",
    "                print(s)\n",
    "                scores.append(s)\n",
    "            print(\"mean scores\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
